---
title: "01 Introduction to modeling"
author: "Edneide Ramalho"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    html_document:
      highlight: textmate
      logo: logo.png
      theme: cerulean
      number_sections: yes
      toc: yes
      toc_float:
        collapsed: yes
        smooth_scroll: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercises

## **Exploratory visualization of age**

Let's perform an exploratory data analysis (EDA) of the numerical explanatory variable `age`. You should always perform an exploratory analysis of your variables before any formal modeling. This will give you a sense of your variable's distributions, any outliers, and any patterns that might be useful when constructing your eventual model.

-   Using the `ggplot2` package, create a histogram of `age` with bins in 5 year increments.

-   Label the `x` axis with `"age"` and the `y` axis with `"count"`.

```{r}
# Load packages
library(moderndive)
library(ggplot2)

# Plot the histogram
ggplot(evals, aes(x = age)) +
  geom_histogram(binwidth = 5) +
  labs(x = "age", y = "count")
```

## **Numerical summaries of age**

Let's continue our exploratory data analysis of the numerical explanatory variable `age` by computing **summary statistics**. Summary statistics take many values and summarize them with a single value. Let's compute three such values using `dplyr` data wrangling: mean (AKA the average), the median (the middle value), and the standard deviation (a measure of spread/variation).

Calculate the mean, median, and standard deviation of `age`.

```{r}
# Load packages
library(moderndive)
library(dplyr)

# Compute summary stats
evals %>%
  summarise(mean_age = mean(age),
            median_age = median(age),
            sd_age = sd(age))
```

# Background on modeling for prediction

**Question**:

> Can we predict the sale price of houses based on their features?

**Variables:**

-   $y$: House sale price

-   $\vec{x}$: Features like `sqft_living`, `condintion`, `bedrooms`, `yr_built`, `waterfront`

```{r}
library(dplyr)
library(moderndive)
glimpse(house_prices)
```

Steps to follow before modeling:

-   Looking at the data

-   Visualization

-   Summary Statistics

## EDA

```{r}
library(ggplot2)
ggplot(house_prices, aes(x = price)) +
  geom_histogram() +
  labs(x = "house price", y = "count")
```

-   The majority of the houses is less than 2 million dollars

-   There are few houses with prices close to 8 million dollars

-   The price distribution is right-skewed (it shows a long right tail )

## Log10 Transformation

```{r}
house_prices <- house_prices %>% 
  mutate(log10_price = log10(price)) 
```

```{r}
ggplot(house_prices, aes(x = log10_price)) +
  geom_histogram() +
  labs(x = "log10 house price", y = "count")
```

-   With the log transformation, price distribution is less skewed and more symmetrical.

## Exercises

# **Exploratory visualization of house size**

Let's create an exploratory visualization of the predictor variable reflecting the size of houses: `sqft_living` the square footage of living space where 1 sq.foot â‰ˆ 0.1 sq.meter.

After plotting the histogram, what can you say about the distribution of the variable `sqft_living`?

##### 

-   Create a histogram of `sqft_living`.

-   Label the `x` axis with `"Size (sq.feet)"` and the `y` axis with `"count"`.

```{r}
# Load packages
library(moderndive)
library(ggplot2)

# Plot the histogram
ggplot(house_prices, aes(x = sqft_living)) +
  geom_histogram() +
  labs(x = "Size (sq.feet)", y = "count")
```

-   `sqft_living` is right-skewed, as we can see by the long right tail.

## **Log10 transformation of house size**

You just saw that the predictor variable `sqft_living` is *right*-skewed and hence a log base 10 transformation is warranted to unskew it. Just as we transformed the outcome variable `price` to create `log10_price` in the video, let's do the same for `sqft_living`.

-   Using the `mutate()` function from `dplyr`, create a new column `log10_size` and assign it to `house_prices_2` by applying a `log10()` transformation to `sqft_living`.

```{r}
# Load packages
library(moderndive)
library(dplyr)
library(ggplot2)

# Add log10_size
house_prices_2 <- house_prices %>%
  mutate(log10_size = log10(sqft_living))

# Plot the histogram  
ggplot(house_prices_2, aes(x = log10_size)) +
  geom_histogram() +
  labs(x = "log10 size", y = "count")

```

-   The log10 transformation makes the sqft_living much less skewed.

# The modeling problem for explanation

$$
y = f(\vec{x}) + \epsilon
$$

1.  $f()$ and $\epsilon$ are unknown
2.  $n$ observations of $y$ and $\vec{x}$ are known/given in the data
3.  **Goal**: Fit a model $\hat{f}()$ that approximates $f()$ whilhe ignoring $\epsilon$
4.  **Goal restated:** Separate the signal from the noise
5.  Can then generate fitted/predicted values $\hat{y} = \hat{f}(\vec{x})$

## EDA of relationship

```{r}
evals %>% 
  ggplot(aes(x = age, y = score)) +
  geom_point() +
  labs(x = "age", y = "score",
       title = "Teaching score over age")
```

-   We can not see a positive or negative relationship here, because the pattern is not clear.

-   Let's take a look of overplotting: let's add a jitter

```{r}
evals %>% 
  ggplot(aes(x = age, y = score)) +
  geom_jitter() +
  labs(x = "age", y = "score",
       title = "Teaching score over age (jittered)")
```

## Computing the correlation coefficient 

```{r}
evals %>% 
  summarise(correlation = cor(score, age))
```

-   There is a negative correlation, meaning that as the teachers age they get smaller scores. But this correlation coefficient is weak.

## Exercises

# **EDA of relationship of teaching & "beauty" scores**

The researchers in the UT Austin created a "beauty score" by asking a panel of 6 students to rate the "beauty" of all 463 instructors. They were interested in studying any possible impact of "beauty" of teaching evaluation scores. Let's do an EDA of this variable and its relationship with teaching `score`.

From now on, assume that `ggplot2`, `dplyr`, and `moderndive` are all available in your workspace unless you're told otherwise.

-   Create a histogram of `bty_avg` "beauty scores" with bins of size 0.5.

```{r}
# Plot the histogram
ggplot(evals, aes(x = bty_avg)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = "Beauty score", y = "count")
```

-   Create a scatterplot with the outcome variable `score` on the y-axis and the explanatory variable `bty_avg` on the x-axis.

```{r}
# Scatterplot
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_point() +
  labs(x = "beauty score", y = "teaching score")
```

-   Let's now investigate if this plot suffers from *overplotting*, whereby points are stacked perfectly on top of each other, obscuring the number of points involved. You can do this by `jitter`ing the points. Update the code accordingly!

```{r}
# Scatterplot
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  labs(x = "beauty score", y = "teaching score")
```

# **Correlation between teaching and "beauty" scores**

Let's numerically summarize the relationship between teaching `score` and beauty score `bty_avg` using the correlation coefficient. Based on this, what can you say about the relationship between these two variables?

-   Compute the correlation coefficient of `score` and `bty_avg`.

```{r}
# Compute correlation
evals %>%
  summarize(correlation = cor(score, bty_avg))
```

-   Positive correlation, but weak.

# The modeling problem for Prediction

## Difference between explanation and prediciton

1.  **Explanation:** We care about the form of $\hat{f}()$, in particular any values quantifying relationships between $y$ and $\vec{x}$.
2.  **Prediction:** We don't care so much about the form of $\hat{f}()$, only that it yields "good" predictions $\hat{y}$ of $y$ based on $\vec{x}$.
